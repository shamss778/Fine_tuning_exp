{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e78c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import utils # Assuming utils.py contains the train function and LeNet5 model definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35901883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.LeNet5()\n",
    "model.load_state_dict(torch.load('mnist_model.pth'))\n",
    "\n",
    "num_features = model.net[-1].in_features\n",
    "model.net[-1] = nn.Linear(num_features, 10)  # Adjusting the output layer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr=1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "fine_tune_epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ebf7a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4085\n",
      "Epoch 2, Loss: 0.8731\n",
      "Epoch 3, Loss: 0.7377\n",
      "Epoch 4, Loss: 0.6578\n",
      "Epoch 5, Loss: 0.6023\n",
      "Epoch 6, Loss: 0.5601\n",
      "Epoch 7, Loss: 0.5276\n",
      "Epoch 8, Loss: 0.5002\n",
      "Epoch 9, Loss: 0.4770\n",
      "Epoch 10, Loss: 0.4564\n",
      "Epoch 11, Loss: 0.4386\n",
      "Epoch 12, Loss: 0.4232\n",
      "Epoch 13, Loss: 0.4087\n",
      "Epoch 14, Loss: 0.3953\n",
      "Epoch 15, Loss: 0.3834\n",
      "Epoch 16, Loss: 0.3729\n",
      "Epoch 17, Loss: 0.3619\n",
      "Epoch 18, Loss: 0.3520\n",
      "Epoch 19, Loss: 0.3428\n",
      "Epoch 20, Loss: 0.3343\n",
      "Epoch 21, Loss: 0.3262\n",
      "Epoch 22, Loss: 0.3183\n",
      "Epoch 23, Loss: 0.3113\n",
      "Epoch 24, Loss: 0.3037\n",
      "Epoch 25, Loss: 0.2973\n",
      "Epoch 26, Loss: 0.2907\n",
      "Epoch 27, Loss: 0.2844\n",
      "Epoch 28, Loss: 0.2785\n",
      "Epoch 29, Loss: 0.2722\n",
      "Epoch 30, Loss: 0.2665\n",
      "Epoch 31, Loss: 0.2610\n",
      "Epoch 32, Loss: 0.2561\n",
      "Epoch 33, Loss: 0.2506\n",
      "Epoch 34, Loss: 0.2460\n",
      "Epoch 35, Loss: 0.2410\n",
      "Epoch 36, Loss: 0.2357\n",
      "Epoch 37, Loss: 0.2309\n",
      "Epoch 38, Loss: 0.2268\n",
      "Epoch 39, Loss: 0.2227\n",
      "Epoch 40, Loss: 0.2181\n",
      "Epoch 41, Loss: 0.2136\n",
      "Epoch 42, Loss: 0.2098\n",
      "Epoch 43, Loss: 0.2058\n",
      "Epoch 44, Loss: 0.2017\n",
      "Epoch 45, Loss: 0.1977\n",
      "Epoch 46, Loss: 0.1939\n",
      "Epoch 47, Loss: 0.1901\n",
      "Epoch 48, Loss: 0.1865\n",
      "Epoch 49, Loss: 0.1828\n",
      "Epoch 50, Loss: 0.1788\n",
      "Epoch 51, Loss: 0.1758\n",
      "Epoch 52, Loss: 0.1721\n",
      "Epoch 53, Loss: 0.1688\n",
      "Epoch 54, Loss: 0.1660\n",
      "Epoch 55, Loss: 0.1625\n",
      "Epoch 56, Loss: 0.1593\n",
      "Epoch 57, Loss: 0.1563\n",
      "Epoch 58, Loss: 0.1531\n",
      "Epoch 59, Loss: 0.1497\n",
      "Epoch 60, Loss: 0.1468\n",
      "Epoch 61, Loss: 0.1441\n",
      "Epoch 62, Loss: 0.1414\n",
      "Epoch 63, Loss: 0.1382\n",
      "Epoch 64, Loss: 0.1355\n",
      "Epoch 65, Loss: 0.1328\n",
      "Epoch 66, Loss: 0.1300\n",
      "Epoch 67, Loss: 0.1275\n",
      "Epoch 68, Loss: 0.1248\n",
      "Epoch 69, Loss: 0.1221\n",
      "Epoch 70, Loss: 0.1196\n",
      "Epoch 71, Loss: 0.1169\n",
      "Epoch 72, Loss: 0.1150\n",
      "Epoch 73, Loss: 0.1124\n",
      "Epoch 74, Loss: 0.1099\n",
      "Epoch 75, Loss: 0.1076\n",
      "Epoch 76, Loss: 0.1053\n",
      "Epoch 77, Loss: 0.1031\n",
      "Epoch 78, Loss: 0.1011\n",
      "Epoch 79, Loss: 0.0985\n",
      "Epoch 80, Loss: 0.0966\n",
      "Epoch 81, Loss: 0.0943\n",
      "Epoch 82, Loss: 0.0924\n",
      "Epoch 83, Loss: 0.0903\n",
      "Epoch 84, Loss: 0.0886\n",
      "Epoch 85, Loss: 0.0864\n",
      "Epoch 86, Loss: 0.0848\n",
      "Epoch 87, Loss: 0.0823\n",
      "Epoch 88, Loss: 0.0808\n",
      "Epoch 89, Loss: 0.0793\n",
      "Epoch 90, Loss: 0.0769\n",
      "Epoch 91, Loss: 0.0755\n",
      "Epoch 92, Loss: 0.0731\n",
      "Epoch 93, Loss: 0.0719\n",
      "Epoch 94, Loss: 0.0702\n",
      "Epoch 95, Loss: 0.0687\n",
      "Epoch 96, Loss: 0.0675\n",
      "Epoch 97, Loss: 0.0653\n",
      "Epoch 98, Loss: 0.0644\n",
      "Epoch 99, Loss: 0.0630\n",
      "Epoch 100, Loss: 0.0609\n"
     ]
    }
   ],
   "source": [
    "utils.train(model, utils.train_loader, criterion, optimizer, fine_tune_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4061d181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test   : loss=0.8914, acc=0.8343\n"
     ]
    }
   ],
   "source": [
    "utils.test(model, utils.test_loader, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

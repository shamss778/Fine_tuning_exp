{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e8b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torchvision.datasets import SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94fb71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c86fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, mat_file, transform=None):\n",
    "        self.data = sio.loadmat(mat_file)\n",
    "        self.images = self.data['X'].transpose(3, 0, 1, 2)  # Transpose to (N, H, W, C)\n",
    "        self.labels = self.data['y'].squeeze()  # Remove extra dimension\n",
    "        self.labels[self.labels == 10] = 0  # Change label 10 to 0 for digit 0\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67662b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84, 10) \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77776b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "model = LeNet5()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr=0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d98c0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SVHNDataset('/Users/shamsbenmefteh/Documents/Fine_tuning_exp/data/SVHN/train_32x32.mat', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
    "\n",
    "test_dataset = SVHNDataset('/Users/shamsbenmefteh/Documents/Fine_tuning_exp/data/SVHN/test_32x32.mat', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=6, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec584c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6773\n",
      "Epoch 2, Loss: 0.4426\n",
      "Epoch 3, Loss: 0.3973\n",
      "Epoch 4, Loss: 0.3699\n",
      "Epoch 5, Loss: 0.3497\n",
      "Epoch 6, Loss: 0.3374\n",
      "Epoch 7, Loss: 0.3277\n",
      "Epoch 8, Loss: 0.3236\n",
      "Epoch 9, Loss: 0.3149\n",
      "Epoch 10, Loss: 0.3055\n",
      "Epoch 11, Loss: 0.3053\n",
      "Epoch 12, Loss: 0.2999\n",
      "Epoch 13, Loss: 0.2954\n",
      "Epoch 14, Loss: 0.2945\n",
      "Epoch 15, Loss: 0.2901\n",
      "Epoch 16, Loss: 0.2878\n",
      "Epoch 17, Loss: 0.2888\n",
      "Epoch 18, Loss: 0.2875\n",
      "Epoch 19, Loss: 0.2875\n",
      "Epoch 20, Loss: 0.2859\n",
      "Epoch 21, Loss: 0.2797\n",
      "Epoch 22, Loss: 0.2852\n",
      "Epoch 23, Loss: 0.2824\n",
      "Epoch 24, Loss: 0.2784\n",
      "Epoch 25, Loss: 0.2760\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epochs):\n",
    "    for epoch in range(epochs):  # 5 epochs as example\n",
    "        model.train()\n",
    "        running_loss, val_acc = 0.0, 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, val_acc={val_acc/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f72cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test   : loss=0.5253, acc=0.8509\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            preds = model(x)\n",
    "            test_loss += criterion(preds, y).item()\n",
    "            test_acc  += (preds.argmax(1)==y).sum().item()\n",
    "    print(f\"Test   : loss={test_loss/len(test_loader):.4f}, acc={test_acc/len(test_dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, criterion, optimizer, epochs)\n",
    "test(model, test_loader, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
